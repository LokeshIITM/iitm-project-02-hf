âœ… Project Notes: Data Analyst Agent (LLM Project)
ğŸ“Œ Objective
Build and deploy an LLM-powered API that can act as a Data Analyst Agent, capable of:

Reading natural language questions from questions.txt

Optionally handling other files (CSV, JSON, images, PDFs)

Scraping external data (e.g., Wikipedia)

Performing statistical/dataframe analysis

Generating and returning base64-encoded plots

ğŸš€ Project Scope Summary
Task	Description
API	Expose a POST endpoint
Input	questions.txt (required) + optional files
Output	JSON array or object with answers, incl. plots
Time Limit	Response must be returned within 3 minutes
Deployment	Host at a public URL accessible by anyone
Submission	GitHub repo (public) + deployed API URL

ğŸ“¦ Inputs and Output Format
Example Input (POST request):

questions.txt (ALWAYS required)

Optional: data.csv, image.png, meta.json, .pdf files

Example Output (as JSON):

json
Copy
Edit
[
  1,
  "Titanic",
  0.485782,
  "data:image/png;base64,..."
]
ğŸ§ª Evaluation Criteria
Output must be a valid JSON array or object

Youâ€™ll be tested on:

âœ… Correct values (exact match or regex)

âœ… Valid plot generation:

Scatterplot

Labeled axes

Red dotted regression line

Base64 PNG, under 100 KB

No score normalization â€” your score is exactly what promptfoo gives

ğŸ§± Architecture Components
Component	Toolset
API Backend	FastAPI or Flask (Python)
LLM Integration	AIPipe or AIProxy (proxy for OpenAI-like models)
Data Analysis	pandas, numpy, duckdb, seaborn, matplotlib
File Parsing	csv, json, pdfplumber, PyMuPDF, io, etc.
Web Scraping	BeautifulSoup, requests, playwright
Image Encoding	base64, BytesIO
Deployment	Render, Railway, Fly.io, Hugging Face, or persistent ngrok
Storage (Temp)	Local FS or /tmp/ (ephemeral)

ğŸ” LLM Access via AIPipe / AIProxy
Use these instead of direct OpenAI to stay within the $1/month quota.

OpenAI	Replacement
https://api.openai.com/v1	https://aipipe.org/openai/v1 or https://aiproxy.sanand.workers.dev/openai/
OPENAI_API_KEY	AIPIPE_TOKEN or AIPROXY_TOKEN
gpt-4.1-nano	openai/gpt-4.1-nano, google/gemini-2.0-flash-lite-001

Example curl for AIPipe:

bash
Copy
Edit
curl https://aipipe.org/openrouter/v1/chat/completions \
  -H "Authorization: Bearer $AIPIPE_TOKEN" \
  -d '{
    "model": "google/gemini-2.0-flash-lite-001",
    "messages": [{"role": "user", "content": "What is 2+2?"}]
  }'
âœ… Submission Requirements Checklist
You must complete all the following:

âœ… GitHub repo exists and is public

âœ… MIT LICENSE file added at root

âœ… Code is committed and pushed

âœ… App deployed to publicly accessible URL

âœ… Submit both:

GitHub repository URL

Deployed API endpoint URL
(at submission link when live)

ğŸ“Œ Technical Access Checklist
âœ… Use Chrome browser

âœ… Enable JavaScript, cookies

âœ… Disable ad-blockers, tracking blockers, interfering extensions

âœ… Avoid overly strict antivirus

âœ… Submit with your official IITM email:
22f3xxxxxx@ds.study.iitm.ac.in

ğŸ“Š Sample Tasks You Should Handle
Type	Example Description
Scraping	Fetch table from Wikipedia, parse it, analyze it
Analysis	Correlations, rankings, regression from tabular data
Plotting	Scatterplot + regression line + base64 return
File Handling	Accept and parse .csv, .json, .parquet, .pdf
Structured Queries	Run SQL over Indian court data via DuckDB

ğŸ”— External Data Sources
ğŸ“„ 1. Wikipedia â€“ Scraping Example
URL:
https://en.wikipedia.org/wiki/List_of_highest-grossing_films

You must:

Fetch and parse HTML tables

Extract: Rank, Peak, Title, etc.

Perform filtering, aggregation, plotting

ğŸ›ï¸ 2. Indian High Court Judgement Dataset
Hosted on S3 (public):
https://s3.console.aws.amazon.com/s3/buckets/indian-high-court-judgments

Used with DuckDB remote query:

sql
Copy
Edit
INSTALL httpfs;
LOAD httpfs;

INSTALL parquet;
LOAD parquet;

SELECT COUNT(*)
FROM read_parquet(
  's3://indian-high-court-judgments/metadata/parquet/' ||
  'year=*/court=*/bench=*/metadata.parquet' ||
  '?s3_region=ap-south-1'
);
Handles:

Millions of rows of metadata

Delay calculations (judgment date vs. registration)

Court-wise and year-wise aggregations

Visualizations of trends